{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:29:52.797925Z","iopub.execute_input":"2022-10-09T14:29:52.7985Z","iopub.status.idle":"2022-10-09T14:30:01.974009Z","shell.execute_reply.started":"2022-10-09T14:29:52.798465Z","shell.execute_reply":"2022-10-09T14:30:01.972746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from copy import deepcopy\nimport json\nimport random\nimport time\nfrom pathlib import Path\nimport sys\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport tqdm\nfrom torch.utils import data\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torch.nn import functional as fnn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nsys.path.insert(1, '../input/metric-tools-car-places')\nfrom engine import evaluate","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:01.976369Z","iopub.execute_input":"2022-10-09T14:30:01.977096Z","iopub.status.idle":"2022-10-09T14:30:02.007607Z","shell.execute_reply.started":"2022-10-09T14:30:01.977052Z","shell.execute_reply":"2022-10-09T14:30:02.006654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка датасета и модели детекции номеров","metadata":{}},{"cell_type":"code","source":"class CarPlatesDatasetWithRectangularBoxes(data.Dataset):\n    def __init__(self, root, transforms, split='train', train_size=0.7, test_size=0.2):\n        super(CarPlatesDatasetWithRectangularBoxes, self).__init__()\n        self.root = Path(root)\n        self.train_size = train_size\n        \n        self.image_names = []\n        self.image_ids = []\n        self.image_boxes = []\n        self.image_texts = []\n        self.box_areas = []\n        \n        self.transforms = transforms\n        \n        if split in ['train', 'val', 'test']:\n            plates_filename = self.root / 'train.json'\n            with open(plates_filename) as f:\n                json_data = json.load(f)\n            train_test_border = int(len(json_data) * train_size) + 1 # граница между train и test\n            test_val_border = train_test_border + int(len(json_data) * test_size) + 1 # граница между test и valid \n            if split == 'train': data_range = (0, train_test_border)\n            elif split == 'test': data_range = (train_test_border, test_val_border)\n            else: data_range = (test_val_border, len(json_data))\n            self.load_data(json_data[data_range[0]:data_range[1]]) # загружаем названия файлов и разметку\n            return\n\n        raise NotImplemented(f'Unknown split: {split}')\n        \n    def load_data(self, json_data):\n        for i, sample in enumerate(json_data):\n            if sample['file'] == 'train/25632.bmp':\n                continue\n            self.image_names.append(self.root / sample['file'])\n            self.image_ids.append(torch.Tensor([i]))\n            boxes = []\n            texts = []\n            areas = []\n            for box in sample['nums']:\n                points = np.array(box['box'])\n                x_0 = np.min([points[0][0], points[3][0]])\n                y_0 = np.min([points[0][1], points[1][1]])\n                x_1 = np.max([points[1][0], points[2][0]])\n                y_1 = np.max([points[2][1], points[3][1]])\n                \n                if x_0 > x_1:\n                    x_1, x_0 = x_0, x_1\n                if y_0 > y_1:\n                    y_1, y_0 = y_0, y_1\n                boxes.append([x_0, y_0, x_1, y_1])\n                \n                texts.append(box['text'])\n                areas.append(np.abs(x_0 - x_1) * np.abs(y_0 - y_1))\n            boxes = torch.FloatTensor(boxes)\n            areas = torch.FloatTensor(areas)\n            self.image_boxes.append(boxes)\n            self.image_texts.append(texts)\n            self.box_areas.append(areas)\n        \n    \n    def load_test_data(self, plates_filename, split, train_size):\n        df = pd.read_csv(plates_filename, usecols=['file_name'])\n        for row in df.iterrows():\n            self.image_names.append(self.root / row[1][0])\n        self.image_boxes = None\n        self.image_texts = None\n        self.box_areas = None\n         \n    \n    def __getitem__(self, idx):\n        target = {}\n        if self.image_boxes is not None:\n            boxes = self.image_boxes[idx].clone()\n            areas = self.box_areas[idx].clone()\n            num_boxes = boxes.shape[0]\n            target['boxes'] = boxes\n            target['area'] = areas\n            target['labels'] = torch.LongTensor([1] * num_boxes)\n            target['image_id'] = self.image_ids[idx].clone()\n            target['iscrowd'] = torch.Tensor([False] * num_boxes)\n\n        image = cv2.imread(str(self.image_names[idx]))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transforms is not None:\n            image = self.transforms(image)\n        return image, target\n\n    def __len__(self):\n        return len(self.image_names)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:06.283198Z","iopub.execute_input":"2022-10-09T14:30:06.283554Z","iopub.status.idle":"2022-10-09T14:30:06.303167Z","shell.execute_reply.started":"2022-10-09T14:30:06.283524Z","shell.execute_reply":"2022-10-09T14:30:06.301557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\ndef create_model(device):\n    model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n    num_classes = 2  \n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    return model.to(device)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:07.329172Z","iopub.execute_input":"2022-10-09T14:30:07.330115Z","iopub.status.idle":"2022-10-09T14:30:07.337403Z","shell.execute_reply.started":"2022-10-09T14:30:07.330068Z","shell.execute_reply":"2022-10-09T14:30:07.336506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformations= transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                         std=[0.229, 0.224, 0.225])\n                    ])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:07.985389Z","iopub.execute_input":"2022-10-09T14:30:07.985768Z","iopub.status.idle":"2022-10-09T14:30:07.991517Z","shell.execute_reply.started":"2022-10-09T14:30:07.985733Z","shell.execute_reply":"2022-10-09T14:30:07.99044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ntrain_dataset = CarPlatesDatasetWithRectangularBoxes('/kaggle/input/car-plates-ocr/data', transformations, 'train')\nval_dataset = CarPlatesDatasetWithRectangularBoxes('/kaggle/input/car-plates-ocr/data', transformations, 'val')\ntest_dataset = CarPlatesDatasetWithRectangularBoxes('/kaggle/input/car-plates-ocr/data', transformations, 'test')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:09.009631Z","iopub.execute_input":"2022-10-09T14:30:09.010334Z","iopub.status.idle":"2022-10-09T14:30:11.708785Z","shell.execute_reply.started":"2022-10-09T14:30:09.010297Z","shell.execute_reply":"2022-10-09T14:30:11.707789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=2, shuffle=True, num_workers=4,\n    collate_fn=collate_fn)\n\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=2, shuffle=False, num_workers=4,\n    collate_fn=collate_fn)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=2, shuffle=False, num_workers=4,\n    collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T14:30:11.710487Z","iopub.execute_input":"2022-10-09T14:30:11.710964Z","iopub.status.idle":"2022-10-09T14:30:11.719145Z","shell.execute_reply.started":"2022-10-09T14:30:11.710926Z","shell.execute_reply":"2022-10-09T14:30:11.718044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Обучение модели детекции","metadata":{}},{"cell_type":"code","source":"# Часть кода взята из  pytorch utils\nfor optimize in [torch.optim.SGD]:\n    for learning_rate in [0.005, 0.001]:\n        model = create_model(device)\n        \n        params = [p for p in model.parameters() if p.requires_grad]\n        optimizer = optimize(params, lr=learning_rate, weight_decay=0.0005)\n\n        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                                       step_size=3,\n                                                       gamma=0.1)\n\n        num_epochs = 1\n\n        for epoch in range(num_epochs):\n            model.train()\n\n            for images, targets in tqdm.tqdm(train_loader):\n                images = list(image.to(device) for image in images)\n                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n\n                optimizer.zero_grad()\n                losses.backward()\n                optimizer.step()\n\n            batch_losses = []\n            for images, targets in tqdm.tqdm(val_loader):\n                images = list(image.to(device) for image in images)\n                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n                loss_dict = model(images, targets)\n                losses = sum(loss for loss in loss_dict.values())\n                batch_losses.append(losses.item())\n                optimizer.zero_grad()\n\n            batch_losses = np.array(batch_losses)\n            batch_losses = batch_losses[np.isfinite(batch_losses)]\n            print(f'Valid_loss: {np.mean(batch_losses)}')\n            lr_scheduler.step()\n            \n            with open(f'{optimize} {learning_rate}', 'wb') as fp:\n                torch.save(model.state_dict(), fp)\n             \n            print(f\"{optimize} and {learning_rate}: {evaluate(model, test_loader, device=device)}\")\n            \n\nprint(\"That's it!\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-10-09T14:30:35.330111Z","iopub.execute_input":"2022-10-09T14:30:35.330492Z","iopub.status.idle":"2022-10-09T15:38:18.932856Z","shell.execute_reply.started":"2022-10-09T14:30:35.330458Z","shell.execute_reply":"2022-10-09T15:38:18.931659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Проверка качества детекции\n","metadata":{}},{"cell_type":"code","source":"unnormalize_1 = transforms.Normalize(mean=[-0.485, -0.456, -0.406],\n                                         std=[1, 1, 1])\nunnormalize_2 = transforms.Normalize(mean=[0, 0, 0],\n                                         std=[1/0.229, 1/0.224, 1/0.225])\nunnormalize = transforms.Compose([unnormalize_2, unnormalize_1])\n","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:00.400395Z","iopub.execute_input":"2022-10-09T15:39:00.400791Z","iopub.status.idle":"2022-10-09T15:39:00.407881Z","shell.execute_reply.started":"2022-10-09T15:39:00.400759Z","shell.execute_reply":"2022-10-09T15:39:00.406909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detach_dict(pred):\n    return{k:v.detach().cpu() for (k,v) in pred.items()}","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:01.227862Z","iopub.execute_input":"2022-10-09T15:39:01.228235Z","iopub.status.idle":"2022-10-09T15:39:01.233532Z","shell.execute_reply.started":"2022-10-09T15:39:01.228202Z","shell.execute_reply":"2022-10-09T15:39:01.232286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = 0\n\nimages = []\nfor i in range(start, start + 1):\n    images.append(test_dataset[i][0].to(device))","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:03.485403Z","iopub.execute_input":"2022-10-09T15:39:03.486522Z","iopub.status.idle":"2022-10-09T15:39:03.632424Z","shell.execute_reply.started":"2022-10-09T15:39:03.486475Z","shell.execute_reply":"2022-10-09T15:39:03.631424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\npreds = model(images)\npreds = [detach_dict(pred) for pred in preds]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:05.116239Z","iopub.execute_input":"2022-10-09T15:39:05.1166Z","iopub.status.idle":"2022-10-09T15:39:05.146349Z","shell.execute_reply.started":"2022-10-09T15:39:05.116571Z","shell.execute_reply":"2022-10-09T15:39:05.145427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots(1, 2, figsize = (20, 8))\n\nfor i in range(1):\n    image = unnormalize(images[i].clone().cpu())\n    ax[i].imshow(image.numpy().transpose([1,2,0]))\n    for box in preds[i]['boxes']:\n        box = box.detach().cpu().numpy()\n        rect = patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1],linewidth=1,edgecolor='r',facecolor='none')\n        ax[i].add_patch(rect)\n\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-10-09T15:39:06.916159Z","iopub.execute_input":"2022-10-09T15:39:06.916529Z","iopub.status.idle":"2022-10-09T15:39:08.066909Z","shell.execute_reply.started":"2022-10-09T15:39:06.9165Z","shell.execute_reply":"2022-10-09T15:39:08.065906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Выделение номеров с картинок","metadata":{}},{"cell_type":"code","source":"x0 = int(box[0])-20\nx1 = int(box[2])+20\ny0 = int(box[1])-20\ny1 = int(box[3])+20\n\nplt.imshow(images[0].cpu().numpy().transpose([1,2,0])[y0:y1, x0:x1])","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:14.548161Z","iopub.execute_input":"2022-10-09T15:39:14.548694Z","iopub.status.idle":"2022-10-09T15:39:14.809681Z","shell.execute_reply.started":"2022-10-09T15:39:14.548656Z","shell.execute_reply":"2022-10-09T15:39:14.808767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = unnormalize(images[0]).cpu().numpy().transpose([1,2,0])[y0:y1, x0:x1]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:15.467006Z","iopub.execute_input":"2022-10-09T15:39:15.467729Z","iopub.status.idle":"2022-10-09T15:39:15.481923Z","shell.execute_reply.started":"2022-10-09T15:39:15.467688Z","shell.execute_reply":"2022-10-09T15:39:15.480833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(im)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:17.875431Z","iopub.execute_input":"2022-10-09T15:39:17.875834Z","iopub.status.idle":"2022-10-09T15:39:17.882738Z","shell.execute_reply.started":"2022-10-09T15:39:17.875802Z","shell.execute_reply":"2022-10-09T15:39:17.881769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(im)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:18.668226Z","iopub.execute_input":"2022-10-09T15:39:18.66898Z","iopub.status.idle":"2022-10-09T15:39:18.922887Z","shell.execute_reply.started":"2022-10-09T15:39:18.668943Z","shell.execute_reply":"2022-10-09T15:39:18.921903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imsave('plate.jpg',im)","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:20.707545Z","iopub.execute_input":"2022-10-09T15:39:20.707929Z","iopub.status.idle":"2022-10-09T15:39:20.71927Z","shell.execute_reply.started":"2022-10-09T15:39:20.707894Z","shell.execute_reply":"2022-10-09T15:39:20.718208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import easyocr","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:21.774413Z","iopub.execute_input":"2022-10-09T15:39:21.774876Z","iopub.status.idle":"2022-10-09T15:39:22.32448Z","shell.execute_reply.started":"2022-10-09T15:39:21.774806Z","shell.execute_reply":"2022-10-09T15:39:22.32349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reader = easyocr.Reader(['ru','en'])\nres = reader.readtext('plate.jpg', decoder = 'beamsearch', allowlist = 'УКЕНХВАРОСМИТ1234567890RUS')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:22.773653Z","iopub.execute_input":"2022-10-09T15:39:22.77628Z","iopub.status.idle":"2022-10-09T15:39:27.078774Z","shell.execute_reply.started":"2022-10-09T15:39:22.77624Z","shell.execute_reply":"2022-10-09T15:39:27.077793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plate_num = res[0][1]\nplate_score = res[0][2]","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:27.080476Z","iopub.execute_input":"2022-10-09T15:39:27.080823Z","iopub.status.idle":"2022-10-09T15:39:27.085257Z","shell.execute_reply.started":"2022-10-09T15:39:27.080794Z","shell.execute_reply":"2022-10-09T15:39:27.084215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots() \nimage = unnormalize(images[0].clone().cpu())\nax.imshow(image.numpy().transpose([1,2,0]))\nrect = patches.Rectangle((x0,y0),x1-x0,y1-y0,linewidth=1,edgecolor='r',facecolor='none')\nax.add_patch(rect)\nax.text(x0, y1+50, f'License plate: {plate_num}', color = 'white')\nax.text(x0, y1+110, f'Probability: {plate_score*100:.2f} %', color = 'white')","metadata":{"execution":{"iopub.status.busy":"2022-10-09T15:39:27.086867Z","iopub.execute_input":"2022-10-09T15:39:27.087479Z","iopub.status.idle":"2022-10-09T15:39:28.150897Z","shell.execute_reply.started":"2022-10-09T15:39:27.087441Z","shell.execute_reply":"2022-10-09T15:39:28.14982Z"},"trusted":true},"execution_count":null,"outputs":[]}]}